<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>机器人中的数值优化（三） | Arvin</title><meta name="author" content="Arvin"><meta name="copyright" content="Arvin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="文档维护：Arvin 网页部署：Arvin ▶ 写在前面：本文内容是作者在深蓝学院机器人中的数值优化学习时的笔记，作者按照自己的理解进行了记录，如果有错误的地方还请执政。如涉侵权，请联系删除。 有约束优化（笔记）分类 低维线性规划（LP）目标函数：$$f(x_1,x_2\ldots x_d)&#x3D;c_1x_1+c_2x_2+\cdots+c_dx_d$$约束：$$\begin{array}{">
<meta property="og:type" content="article">
<meta property="og:title" content="机器人中的数值优化（三）">
<meta property="og:url" content="http://example.com/2024/02/20/304-2024-02-20-Math-Optimization/index.html">
<meta property="og:site_name" content="Arvin">
<meta property="og:description" content="文档维护：Arvin 网页部署：Arvin ▶ 写在前面：本文内容是作者在深蓝学院机器人中的数值优化学习时的笔记，作者按照自己的理解进行了记录，如果有错误的地方还请执政。如涉侵权，请联系删除。 有约束优化（笔记）分类 低维线性规划（LP）目标函数：$$f(x_1,x_2\ldots x_d)&#x3D;c_1x_1+c_2x_2+\cdots+c_dx_d$$约束：$$\begin{array}{">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/nacho.jepg">
<meta property="article:published_time" content="2024-02-19T16:00:00.000Z">
<meta property="article:modified_time" content="2025-08-19T08:41:22.420Z">
<meta property="article:author" content="Arvin">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/nacho.jepg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "机器人中的数值优化（三）",
  "url": "http://example.com/2024/02/20/304-2024-02-20-Math-Optimization/",
  "image": "http://example.com/img/nacho.jepg",
  "datePublished": "2024-02-19T16:00:00.000Z",
  "dateModified": "2025-08-19T08:41:22.420Z",
  "author": [
    {
      "@type": "Person",
      "name": "Arvin",
      "url": "http://example.com"
    }
  ]
}</script><link rel="shortcut icon" href="/img/nacho.jpeg"><link rel="canonical" href="http://example.com/2024/02/20/304-2024-02-20-Math-Optimization/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器人中的数值优化（三）',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background: None;"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Arvin</span></a><a class="nav-page-title" href="/"><span class="site-name">机器人中的数值优化（三）</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">机器人中的数值优化（三）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-02-19T16:00:00.000Z" title="Created 2024-02-20 00:00:00">2024-02-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-08-19T08:41:22.420Z" title="Updated 2025-08-19 16:41:22">2025-08-19</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>文档维护：<code>Arvin</code></p>
<p>网页部署：<code>Arvin</code></p>
<p>▶</p>
<p><strong>写在前面</strong>：本文内容是作者在深蓝学院<a target="_blank" rel="noopener" href="https://www.shenlanxueyuan.com/course/659">机器人中的数值优化</a>学习时的笔记，作者按照自己的理解进行了记录，如果有错误的地方还请执政。如涉侵权，请联系删除。</p>
<h1 id="有约束优化（笔记）"><a href="#有约束优化（笔记）" class="headerlink" title="有约束优化（笔记）"></a>有约束优化（笔记）</h1><h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p><img src="/./304-2024-02-20-Math-Optimization/6.png" alt="6"></p>
<h2 id="低维线性规划（LP）"><a href="#低维线性规划（LP）" class="headerlink" title="低维线性规划（LP）"></a>低维线性规划（LP）</h2><p>目标函数：<br>$$<br>f(x_1,x_2\ldots x_d)&#x3D;c_1x_1+c_2x_2+\cdots+c_dx_d<br>$$<br>约束：<br>$$<br>\begin{array}{l}<br>a_{1,1} x_{1}+\cdots+a_{1, d} x_{d} \leqslant b_{1} \<br>a_{2,1} x_{1}+\cdots+a_{2, d} x_{d} \leqslant b_{2} \<br>a_{n, 1} x_{1}+\cdots+a_{n, d} x_{d} \leqslant b_{n} \<br>\end{array}<br>$$<br><img src="/./304-2024-02-20-Math-Optimization/7.png" alt="7"></p>
<p>每个约束表示$\mathbb{R}^d$中的一个半空间，半空间的交集形成可行域，可行域是$\mathbb{R}^d$中的凸多面体。</p>
<p>我们使$\vec{c}&#x3D;(c_1,c_2,\ldots c_d)$（即目标函数梯度），沿此方向最前的那个点$v_{opt}$就是LP问题的解。</p>
<p><img src="/./304-2024-02-20-Math-Optimization/8.png" alt="8"></p>
<p><strong>一维</strong></p>
<p>目标函数：<br>$$<br>f(x)&#x3D;cx<br>$$<br>约束：<br>$$<br>\begin{array}{l}a_1x\leqslant b_1\a_2x\leqslant b_2\\vdots&amp;\vdots\a_nx\leqslant b_n\end{array}<br>$$<br><img src="/./304-2024-02-20-Math-Optimization/9.png" alt="9"></p>
<p><strong>二维</strong>：</p>
<p><img src="/./304-2024-02-20-Math-Optimization/10.png" alt="10"></p>
<p><img src="/./304-2024-02-20-Math-Optimization/11.png" alt="11"></p>
<p><img src="/./304-2024-02-20-Math-Optimization/12.png" alt="12"></p>
<p><img src="/./304-2024-02-20-Math-Optimization/13.png" alt="13"></p>
<p>当新约束的半空间包含原可行域时，$v_{opt}$不变。</p>
<p><img src="/./304-2024-02-20-Math-Optimization/15.png" alt="15"></p>
<p>其伪代码如下：</p>
<p><img src="/./304-2024-02-20-Math-Optimization/14.png" alt="14"></p>
<h2 id="低维二次规划（QP）"><a href="#低维二次规划（QP）" class="headerlink" title="低维二次规划（QP）"></a>低维二次规划（QP）</h2><p>目标函数及约束（考虑严格凸低维QP问题）：<br>$$<br>\begin{aligned}\min_{x\in\mathbb{R}^n}\frac{1}{2}x^\mathrm{T}M_{\mathcal{Q}}x+c_{\mathcal{Q}}^\mathrm{T}x\text{, s.t. }A_{\mathcal{Q}}x\le b_{\mathcal{Q}}\end{aligned}<br>$$<br>因为是严格凸的，所以$M_{\mathcal{Q}}\succ0$，且是对称的所以可以进行分解：<br>$$<br>M_{\mathcal{Q}}&#x3D;L_{\mathcal{Q}}L_{\mathcal{Q}}^{\mathrm{T}}<br>$$<br>我们将其构造成求最小范数问题：<br>$$<br>\min_{y\in\mathbb{R}^n}\frac12y^\mathrm{T}y,\mathrm{<del>s.t.</del>}Ey\leq f<br>$$<br>其中：<br>$$<br>E&#x3D;A_{\mathcal Q}L_{\mathcal Q}^{-\mathrm{T}},f&#x3D;A_{\mathcal Q}\big(L_{\mathcal Q}L_{\mathcal Q}^{\mathrm{T}}\big)^{-1}c_{\mathcal Q}+b_{\mathcal Q}<br>$$<br>是如何构造成上述形式呢？<br>$$<br>y&#x3D;L_{\mathcal Q}^{\mathrm T}x+L_{\mathcal Q}^{-1}c_{\mathcal Q}\quad\mathrm{or}\quad x&#x3D;L_{\mathcal Q}^{-\mathrm T}y-\left(L_{\mathcal Q}L_{\mathcal Q}^{\mathrm T}\right)^{-1}c_{\mathcal Q}<br>$$<br>即我们先求得最小范数问题的解$y^*$，再根据上式求得$x^*$。</p>
<p>如下图所示：</p>
<p><img src="/./304-2024-02-20-Math-Optimization/16.png" alt="16"></p>
<p>其伪代码为：</p>
<p><img src="/./304-2024-02-20-Math-Optimization/17.png" alt="17"></p>
<h2 id="约束优化的三种序列无约束优化方法"><a href="#约束优化的三种序列无约束优化方法" class="headerlink" title="约束优化的三种序列无约束优化方法"></a>约束优化的三种序列无约束优化方法</h2><h3 id="外点罚函数法"><a href="#外点罚函数法" class="headerlink" title="外点罚函数法"></a>外点罚函数法</h3><blockquote>
<p>参考链接：<a target="_blank" rel="noopener" href="https://openrsl.blog.csdn.net/article/details/129127355?spm=1001.2014.3001.5502">内点罚函数和外点罚函数的优缺点</a></p>
</blockquote>
<p>简而言之，外点罚函数法是指对于可行域外的点，惩罚项为正，即对该点进行惩罚；对于可行域内的点，惩罚项为0，即不做任何惩罚。因此，该算法在迭代过程中点列一般处于可行域之外，惩罚项会促使无约束优化问题的解落在可行域内。罚函数一般由约束部分乘正系数组成，通过增大该系数，我们可以更严厉地惩罚违反约束的行为，从而迫使惩罚函数的最小值更接近约束问题的可行区域。</p>
<p>$L_2-Penalty; Function: Equality; Constrained; Case$</p>
<p>只具有等式约束的规划问题：<br>$$<br>\begin{array}{cc}\min_x&amp;f(x)\\mathrm{s.t.}&amp;c_i(x)&#x3D;0,\quad i\in\mathcal{E}\end{array}<br>$$<br>该规划问题的惩罚函数为：<br>$$<br>P_E(x,\sigma)&#x3D;f(x)+\color{red}{\frac{1}{2}}\sigma\sum_{i\in\mathcal{E}}c_i^2(x)<br>$$<br>红色部分是二次惩罚函数，其中$\sigma$是惩罚权重。</p>
<p>一般的，随着惩罚权重的增加，无约束的最小值接近受约束的最小值。<br>$$<br>\lim_{\sigma\to+\infty}\operatorname{argmin}<em>{x}P</em>{E}(x,\sigma)&#x3D;\operatorname{argmin}<em>{x}f(x),\text{s.t.}c</em>{i}(x)&#x3D;0,i\in\mathcal{E}<br>$$<br>$L_2-Penalty; Function: Inequality; Constrained; Case$</p>
<p>对于不等式约束的规划问题：<br>$$<br>\begin{array}{cc}\min&amp;f(x)\\mathrm{s.t.}&amp;c_i(x)\leqslant0,\quad i\in\mathcal{I}\end{array}<br>$$<br>其惩罚函数为：<br>$$<br>P_I(x,\sigma)&#x3D;f(x)+\color{red}{\frac{1}{2}}\sigma\sum_{i\in\mathcal{I}}\max[c_i(x),0]^2<br>$$<br>同样的上述式子的红色部分是二次惩罚项，但是其二阶导数不是连续的。</p>
<p>随着惩罚权重的增加，无约束的最小值接近受约束的最小值。<br>$$<br>\lim\limits_{\sigma\to+\infty}\operatorname{argmin}<em>{x}P</em>{I}(x,\sigma)&#x3D;\operatorname{argmin}<em>{x}f(x),\text{s.t.}c</em>{i}(x)\leq0,i\in\mathcal{I}<br>$$<br>优点：</p>
<ul>
<li>将约束优化问题转化为无约束优化问题，当$c_i(x)$光滑时可以调用一般的无约束光滑优化问题算法求解; </li>
<li>二次罚函数形式简洁直观而在实际中广泛使用。</li>
</ul>
<p>缺点：</p>
<ul>
<li>需要$\sigma\rightarrow\infty $，此时海瑟矩阵条件数过大，对于无约束优化问题的数值方法拟牛顿法与共轭梯度法存在数值困难，且需要多次迭代求解子问题；</li>
<li>对于存在不等式约束的$P(x,\sigma)$可能不存在二次可微性质，光滑性降低;</li>
<li>不精确，与原问题最优解存在距离。</li>
</ul>
<p>$L_1-Penalty; Function: Exactness$</p>
<p>由于L2-罚函数法存在数值困难，并且与原问题的解存在误差，因此考虑精确罚函数法。精确罚函数是一种问题求解时不需要令罚因子趋于正无穷（或零）的罚函数。换句话说，若罚因子选取适当，对罚函数进行极小化得到的解恰好就是原问题的精确解。这个性质在设计算法时非常有用，使用精确罚函数的算法通常会有比较好的性质。由于L1-罚函数非光滑，因此无约束优化问题P的收敛速度无法保证，这实际上就相当于用牺牲收敛速度的方式来换取优化问题P的精确最优解。</p>
<p>一般的具有约束的优化问题同时包含等式约束和不等式约束：<br>$$<br>\begin{array}{rl}\min&amp;f(x)\\mathrm{s.t.}&amp;c_i(x)&#x3D;0,&amp;i\in\mathcal{E}\&amp;c_j(x)\leqslant0,&amp;j\in\mathcal{I}\end{array}<br>$$<br>其惩罚函数是：<br>$$<br>P(x,\sigma)&#x3D;f(x)+\color{red}{\sigma\sum_{i\in\mathcal{E}}|c_i(x)|+\sigma\sum_{j\in\mathcal{I}}\max[c_j(x),0]}<br>$$<br>红色部分是L1惩罚函数，他的导数是不连续的。</p>
<p>有：<br>$$<br>\exists M\in\mathbb{R}_{&gt;0},\forall\sigma&gt;M,\operatorname{argmin}_xP(x,\sigma)&#x3D;\operatorname{argmin}_xf(x),\operatorname{s.t.}c_i(x)&#x3D;0,i\in\mathcal{E},c_j(x)\leq0,j\in\mathcal{I}<br>$$</p>
<h3 id="内点罚函数法：障碍函数法"><a href="#内点罚函数法：障碍函数法" class="headerlink" title="内点罚函数法：障碍函数法"></a>内点罚函数法：障碍函数法</h3><p>前面介绍的L1和L2罚函数均属于外点罚函数，即在求解过程中允许自变量$x$位于原问题可行域之外，当罚因子趋于无穷时，子问题最优解序列从可行域外部逼近最优解。自然地，如果我们想要使得子问题最优解序列从可行域内部逼近最优解，则需要构造内点罚函数。顾名思义，内点罚函数在迭代时始终要求自变量$x$不能违反约束，因此它主要用于不等式约束优化问题。</p>
<p>如下图所示，考虑含不等式约束的优化问题，为了使迭代点始终在可行域内，当迭代点趋于可行域边界时，我们需要罚函数趋于正无穷。常见的罚函数有三种：对数罚函数，逆罚函数和指数罚函数。对于原问题，它的最优解通常位于可行域边界，即$c_{i}\left(x\right)\leq0$中至少有一个取到等号，此时需要调整惩罚因子$\sigma$使其趋于0，这会减弱障碍罚函数在边界附近的惩罚效果。</p>
<p>不等式约束的规划问题：<br>$$<br>\begin{array}{cc}\min&amp;f(x)\\mathrm{s.t.}&amp;c_i(x)\leqslant0,\quad i\in\mathcal{I}\end{array}<br>$$<br>三种障碍函数的式子为：</p>
<ul>
<li><p>对数障碍函数：<br>$$<br>B_{\ln}(x,\sigma)&#x3D;f(x)-\color{red}\sigma\sum_{i\in\mathcal{I}}\ln(-c_i(x))<br>$$</p>
</li>
<li><p>逆障碍函数：<br>$$<br>B_{\mathrm{inv}}(x,\sigma)&#x3D;f(x)+\color{red}\sigma\sum_{i\in\mathcal{I}}\text{inv}(-c_i(x)),\text{inv}(x):&#x3D;1&#x2F;x\text{if}x&gt;0<br>$$</p>
</li>
<li><p>指数障碍函数：<br>$$<br>B_\text{expi}(x,\sigma)&#x3D;f(x)+\color{red}{\sigma\sum_{i\in\mathcal{I}}\text{expi}(-c_i(x))},\text{expi}(x):&#x3D;e^{1&#x2F;x}\text{if}x&gt;0<br>$$</p>
</li>
</ul>
<p>通常地，随着权重的衰减，无约束的最小值接近受约束的最小值<br>$$<br>\lim_{\sigma\to0^+}\operatorname{argmin}_xB(x,\sigma)&#x3D;\operatorname{argmin}_xf(x),\mathrm{s.t.~}c_i(x)\leq0,i\in\mathcal{I}<br>$$<br><strong>总结</strong></p>
<p>如下图所示，无论是外点惩罚法或者是内点惩罚法，随着权重趋于无穷或者趋于0都会导致函数变得不光滑，海森矩阵条件数趋于无穷，因此使用数值方法（拟牛顿法等）求解会越来越困难。</p>
<p><img src="/./304-2024-02-20-Math-Optimization/1.png" alt="1"></p>
<h3 id="等式约束优化问题的拉格朗日松弛法"><a href="#等式约束优化问题的拉格朗日松弛法" class="headerlink" title="等式约束优化问题的拉格朗日松弛法"></a>等式约束优化问题的拉格朗日松弛法</h3><blockquote>
<p>参考链接：</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1HP4y1Y79e/?spm_id_from=333.337.search-card.all.click&vd_source=a72f6fb4092e6bfd554f97eb9e72c2b2">“拉格朗日对偶问题”如何直观理解？</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/frostime/article/details/90291392">【数学】拉格朗日对偶，从0到完全理解_拉格朗日法对偶格式</a></p>
</blockquote>
<p>等式约束<strong>凸</strong>优化问题：<br>$$<br>\begin{array}{ll}\min_x&amp;f(x)\\mathrm{s.t.}&amp;Ax&#x3D;b\end{array}<br>$$<br>拉格朗日函数：<br>$$<br>\mathcal{L}(x,\lambda):&#x3D;f(x)+\langle\lambda,Ax-b\rangle&#x3D;f(x)+\lambda^{T}(Ax-b)<br>$$<br>显然有：<br>$$<br>\left.\max_{\lambda}f(x)+\langle\lambda,Ax-b\rangle&#x3D;\left{\begin{matrix}f(x),Ax-b&#x3D;0\\infty,\mathrm{~otherwise}\end{matrix}\right.\right.<br>$$<br>因此优化问题等价于，<br>$$<br>\min_xf(x),\text{ s.t. }Ax&#x3D;b\quad\longleftrightarrow\quad\min_x\max_\lambda\mathcal{L}(x,\lambda)<br>$$<br>约束优化问题的最优解正是拉格朗日的<strong>鞍点</strong>。</p>
<p><img src="/./304-2024-02-20-Math-Optimization/18.png" alt="18"></p>
<p><strong>Uzawa’s Method</strong></p>
<p><img src="/./304-2024-02-20-Math-Optimization/2.png" alt="2"></p>
<p>综上分析，Uzawa’s Method迭代过程分为两个步骤<br>$$<br>\left.\left{\begin{array}{l}x^{k+1}&#x3D;\operatorname{argmin}\mathcal{L}\left(x,\lambda^k\right)\\lambda^{k+1}&#x3D;\lambda^k+\alpha\left(Ax^{k+1}-b\right)\end{array}\right.\right.<br>$$</p>
<ol>
<li>给定$\lambda^{k}$，求解$\operatorname*{min}_{x}\mathcal{L}(x,\lambda^{k})$无约束优化问题，求解得到$x^{k+1}$</li>
<li>更新$\lambda$，$L(x^{k+1},\lambda)$关于$\lambda$的梯度为$\left.\frac{\partial L}{\partial\lambda}\right|<em>{x+1}&#x3D;Ax^{k+1}-b$，若要求解$\operatorname*{max}</em>{\lambda}\mathcal{L}(x^{k+1},\lambda)$，则沿着梯度上升方向进入步长迭代，即$\lambda^{k+1}&#x3D;\lambda^k+\alpha\left(Ax^{k+1}-b\right)$，$\sigma$为迭代步长。</li>
</ol>
<p>该方法的前提就是原函数连续凸，$\mathcal{L}(x,\lambda)$关于$x$严格凸，则$\operatorname*{min}_{x}\mathcal{L}(x,\lambda^{k})$只存在一个最优解，可求出唯一$x^{k+1}$进而更新$\lambda^{k+1}$，否则$x^{k+1}$会存在多个，不知道选择哪个去更新$\lambda$。因此缺点很明显，该方法要求原函数必须为连续凸函数，梯度上升步长需要调整且收敛速率不能保证。 </p>
<ul>
<li>原始优化问题应该是凸的。</li>
<li>关于原始变量的拉格朗日函数应该是严格凸的。</li>
<li>对偶上升步长需要调整。</li>
<li>收敛速度不理想。</li>
</ul>
<h2 id="一般约束优化的方法"><a href="#一般约束优化的方法" class="headerlink" title="一般约束优化的方法"></a>一般约束优化的方法</h2><h3 id="KKT条件"><a href="#KKT条件" class="headerlink" title="KKT条件"></a>KKT条件</h3><blockquote>
<p>参考链接：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/38163970">Karush-Kuhn-Tucker (KKT)条件</a></p>
</blockquote>
<p>Karush-Kuhn-Tucker (KKT)条件是非线性规划(nonlinear programming)最佳解的必要条件。KKT条件将Lagrange乘数法(Lagrange multipliers)所处理涉及等式的约束优化问题推广至不等式。在实际应用上，KKT条件(方程组)一般不存在代数解，许多优化算法可供数值计算选用。</p>
<p>一般的约束优化问题<br>$$<br>\begin{array}{ll}\min_x&amp;f(x)\\mathrm{s.t.}&amp;h_i(x)\leq0,i&#x3D;1,\ldots,m\&amp;\ell_j(x)&#x3D;0,j&#x3D;1,\ldots,r\end{array}<br>$$<br>如果上述优化问题没有退化即不等式约束起了作用（这句话具体理解可以看参考链接），它的最优解满足：</p>
<ul>
<li><p>stationarity<br>$$<br>0\in\partial_x[f(x)+\sum_{i&#x3D;1}^mu_ih_i(x)+\sum_{j&#x3D;1}^rv_j\ell_j(x)]<br>$$</p>
</li>
<li><p>complementary slackness<br>$$<br>u_i\cdot h_i(x)&#x3D;0,i&#x3D;1,\ldots,m<br>$$</p>
</li>
<li><p>primal feasibility<br>$$<br>h_i(x)\leq0,\ell_j(x)&#x3D;0,i&#x3D;1,\ldots,m,j&#x3D;1,\ldots,r<br>$$</p>
</li>
<li><p>dual feasibility<br>$$<br>u_{i}\geq0,i&#x3D;1,\ldots,m<br>$$</p>
</li>
</ul>
<h3 id="Powell-Hestense-Rockafellar-Augmented-Lagrangian-Method（PHR-ALM）"><a href="#Powell-Hestense-Rockafellar-Augmented-Lagrangian-Method（PHR-ALM）" class="headerlink" title="Powell-Hestense-Rockafellar Augmented-Lagrangian-Method（PHR-ALM）"></a>Powell-Hestense-Rockafellar Augmented-Lagrangian-Method（PHR-ALM）</h3><blockquote>
<p>参考链接：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_26565435/article/details/129151597">约束优化：PHR-ALM 增广拉格朗日函数法</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1HP4y1Y79e/?spm_id_from=333.337.search-card.all.click&vd_source=a72f6fb4092e6bfd554f97eb9e72c2b2">“拉格朗日对偶问题”如何直观理解？</a></p>
</blockquote>
<p><img src="/./304-2024-02-20-Math-Optimization/3.png" alt="3"></p>
<p><strong>对于等式约束优化问题：</strong><br>$$<br>\begin{aligned}\min_{x\in\mathbb{R}^n}&amp;f(x)\\text{s.t.}&amp;h(x)&#x3D;0\end{aligned}<br>$$<br>Uzawa的方法是对偶函数进行双梯度上升：<br>$$<br>d(\lambda):&#x3D;\min_xf(x)+\lambda^\text{T}h(x)<br>$$<br>如果关于x的拉格朗日函数不是严格凸的，对偶函数就是非光滑的。那么其梯度就可能不存在，这是这种方法就会出现问题。</p>
<p>已知$\left.\operatorname*{max}<em>{\lambda}f(x)+\lambda^{\mathrm{T}}h(x)&#x3D;\left{\begin{array}{l}{f(x),h(x)&#x3D;0}\{\infty,\mathrm{~otherwise}}\end{array}\right.\right.$是一个不连续函数，如何处理这个不连续的函数，一个非常直观的方法就是将该问题近似成一个连续问题，这是PHR的基本思想。如何近似呢？增加一项$\frac{1}{2\rho}|\lambda-\bar{\lambda}|^2$，用来近似平滑原来不连续的函数$\max</em>{\lambda}f(x)+\lambda^{\mathrm{T}}h(x)$，其中$\rho&gt;0$用来惩罚$\lambda$与先验值$\bar{\lambda}$之间的偏差。<br>$$<br>\min_x\max_\lambda f(x)+\lambda^\text{T}h(x)-\color{red}\frac{1}{2\rho}|\lambda-\bar{\lambda}|^2<br>$$<br>这样一来，函数被近似成一个光滑函数，同时$f(x)+\lambda^{\mathrm{T}}h(x)$是关于$\lambda$的线性函数，既是凸函数又是凹函数，而且$-\frac1{2\rho}|\lambda-\bar{\lambda}|^2$是关于$\lambda$的严格凹函数，因此整个函数仍为严格凹，对于严格凹问题$\operatorname*{max}_{\lambda}f(x)+\lambda^{\mathrm{T}}h(x)-\frac{1}{2\rho}|\lambda-\bar{\lambda}|^{2}$有唯一最优解$\lambda^{<em>}$满足：<br>$$<br>\frac{\partial\left{f(x)+\lambda^\top h(x)-\frac1{2\rho}\left|\lambda-\bar\lambda\right|^2\right}}{\partial\lambda}&#x3D;h(x)-\frac1\rho\left(\lambda-\bar{\lambda}\right)&#x3D;0<br>$$<br>可解得<br>$$<br>\lambda^</em>(\bar{\lambda})&#x3D;\bar{\lambda}+\rho h(x)<br>$$<br>带入到原式中：<br>$$<br>\begin{aligned}<br>&amp;\min_x\max_\lambda f(x)+\lambda^\mathrm{T}h(x)-\frac1{2\rho}|\lambda-\bar{\lambda}|^2 \<br>&amp;&#x3D;\min_x\left.f(x)+\lambda^*(\bar{\lambda})^{\mathrm{T}}h(x)-\frac1{2\rho}\left.\right\Vert\lambda^*(\bar{\lambda})-\bar{\lambda}\Vert^2\right.  \<br>&amp;&#x3D;\min_xf(x)+(\bar{\lambda}+\rho h(x))^\text{T}h(x)-\frac\rho2|h(x)|^2 \<br>&amp;&#x3D;\min_xf(x)+\bar{\lambda}^\mathrm{T}h(x)+\frac\rho2|h(x)|^2<br>\end{aligned}<br>$$<br>上述都是近似的过程，但是我们如何确保近似的精度呢？</p>
<ol>
<li>减少近似权重，使$\frac1\rho\to0$或$\rho\to+\infty $</li>
<li>更新先验值$\bar{\lambda}\leftarrow\lambda^{*}(\bar{\lambda})$</li>
</ol>
<p>对于等式约束的PHR更新方法：<br>$$<br>\begin{aligned}<br>&amp;x\leftarrow\arg\min_{x}f(x)+\bar{\lambda}^{\mathrm{T}}h(x)+\frac{\rho}{2}|h(x)|^{2} \<br>&amp;\bar{\lambda}\leftarrow\bar{\lambda}+\rho h(x)<br>\end{aligned}<br>$$<br>拉格朗日函数变为增广拉格朗日函数：<br>$$<br>\min_x\max_\lambda f(x)+\frac{\rho}{2}|h(x)|^2+\lambda^\text{T}h(x)<br>$$<br>明显地，相应的原始问题变为<br>$$<br>\begin{aligned}\min_{x\in\mathbb{R}^n}f(x)+\frac{\rho}{2}|h(x)|^2\\text{s.t.}h(x)&#x3D;0\end{aligned}<br>$$<br>此时得到一个与原问题近似的无约束最优化问题，通过在原拉格朗日函数的基础之上增加一个增广项获得一个增广拉格朗日函数，来得到近似光滑且容易解的优化问题。</p>
<p><strong>对于原本非凸等式约束优化问题：</strong><br>$$<br>\begin{aligned}\min_{x\in\mathbb{R}^n}&amp;f(x)\\text{s.t.}&amp;h(x)&#x3D;0\end{aligned}<br>$$<br>其PHR增广拉格朗日函数的更常用等效形式为：<br>$$<br>\mathcal{L}_{\rho}(x,\lambda):&#x3D;f(x)+\frac{\rho}{2}\Big\Vert h(x)+\frac{\lambda}{\rho}\Big\Vert^{2}<br>$$<br>KKT解析可以通过以下方式解决：<br>$$<br>\begin{cases}x^{k+1}&#x3D;\operatorname{argmin}<em>x\mathcal{L}</em>{\rho^k}(x,\lambda^k)\\lambda^{k+1}&#x3D;\lambda^k+\rho^kh\big(x^{k+1}\big)\\rho^{k+1}&#x3D;\min[(1+\gamma)\rho^k,\beta]\end{cases}<br>$$</p>
<ul>
<li>$p^k$迭代过程不是下降的，$\gamma\geq0,\beta&gt;0,\rho^{0}&gt;0$</li>
<li>不需要每次都求解很精确的$x^k$，因为外循环会不断的细化$\lambda^{k}$和$x^k$</li>
</ul>
<p><strong>对于不等式约束非凸优化问题：</strong></p>
<p>对于不等式约束的非凸问题，核心思想是通过引入松弛变量$s$，将不等式约束转化为等式约束，然后再写成增广拉格朗日函数形式。如下图所示，引入松弛变量$s$，原问题维度从n维上升到n+m维。原问题为：<br>$$<br>\begin{array}{rl}\min_{x\in\mathbb{R}^n}&amp;f(x)\\mathrm{s.t.}&amp;g(x)\leq0\end{array}<br>$$<br>引入松弛变量后变为等式约束的非凸优化问题：<br>$$<br>\begin{aligned}&amp;\min_{x\in\mathbb{R}^n,s\in\mathbb{R}^m}f(x)\&amp;\mathrm{s.t.}\quad g(x)+[s]^2&#x3D;0\end{aligned}<br>$$<br>将转化后的问题写成增广拉格朗日函数形式：<br>$$<br>\min_{x\in\mathbb{R}^n,s\in\mathbb{R}^m}f(x)+\frac\rho2\left|g(x)+[s]^2+\frac\lambda\rho\right|^2&#x3D;\min_{x\in\mathbb{R}^n}\min_{s\in\mathbb{R}^m}f(x)+\frac\rho2\left|g(x)+[s]^2+\frac\lambda\rho\right|^2&#x3D;\min_{x\in\mathbb{R}^n}f(x)+\color{red}{\frac\rho2}\left|\max\left[g(x)+\frac\lambda\rho,0\right]\right|^2<br>$$<br>为了与等式约束拉格朗日乘子区别开我们将$\lambda$写成$\mu$<br>$$<br>\mathcal{L}_{\rho}(x,\mu):&#x3D;f(x)+\frac{\rho}{2}\Big\Vert\max\big[g(x)+\frac{\mu}{\rho},0\big]\Big|^{2}<br>$$</p>
<p>其中$\rho&gt;0,\mu\succeq0$。PHR-ALM只是重复下降+对偶函数上升迭代。<br>$$<br>\begin{cases}x\leftarrow\operatorname{argmin}_x\mathcal{L}_\rho(x,\lambda,\mu)\\lambda\leftarrow\lambda+\rho h(x)\\mu\leftarrow\max[\mu+\rho g(x),0]\\rho\leftarrow\min[(1+\gamma)\rho,\beta]\end{cases}<br>$$</p>
<ul>
<li><p>如何选择参数<br>$$<br>\rho_{\mathrm{ini}}&#x3D;1,\lambda_{\mathrm{ini}}&#x3D;\mu_{\mathrm{ini}}&#x3D;0,\gamma&#x3D;1,\beta&#x3D;10^3<br>$$</p>
</li>
<li><p>内层循环迭代停止条件，内层循环就是解无约束优化问题<br>$$<br>\left.|\nabla_x\mathcal{L}_\rho(x,\lambda,\mu)|_\infty&lt;\xi^k\min\left[1,\max\left[|h(x)|_\infty,\right|\max\left[g(x),-\frac\mu\rho\right]\right|_\infty\right]\text{with positive }\xi^k\text{ converging to }0<br>$$</p>
</li>
<li><p>外层迭代停止条件，即度量KKT条件的残差<br>$$<br>\max\left[\left|h(x)\right|<em>{\infty},\left|\max\left[g(x),-\frac{\mu}{\rho}\right]\right|</em>{\infty}\right]&lt;\epsilon_{\mathrm{cons}},\left|\nabla_{x}{\mathcal L}<em>{\rho}(x,\lambda,\mu)\right|</em>{\infty}&lt;\epsilon_{\mathrm{prec}}<br>$$</p>
</li>
</ul>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><blockquote>
<p>参考链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_44339029/article/details/132168000">约束优化的应用：控制分配问题、碰撞距离计算、非线性MPC</a></p>
</blockquote>
<p>控制分配问题、碰撞距离计算、非线性模型预测控制</p>
<h1 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h1><h2 id="作业一：严格凸的等式约束QP的KKT推导和求解"><a href="#作业一：严格凸的等式约束QP的KKT推导和求解" class="headerlink" title="作业一：严格凸的等式约束QP的KKT推导和求解"></a>作业一：严格凸的等式约束QP的KKT推导和求解</h2><p>问题如下：<br>$$<br>\begin{aligned}\min_{x\in\mathbb{R}^n}\frac{1}{2}x^\top Qx+c^\top x\s.t.Ax&#x3D;b\end{aligned}<br>$$<br>其中$Q$是对称正定矩阵（spd）。</p>
<p>根据课程所学，它的最优解满足：</p>
<ul>
<li><p>stationarity<br>$$<br>0\in\partial_x[f(x)+\sum_{i&#x3D;1}^mu_ih_i(x)+\sum_{j&#x3D;1}^rv_j\ell_j(x)]<br>$$<br>即：<br>$$<br>\partial_x[\frac{1}{2}x^\top Qx+c^\top x+v(Ax-b)]&#x3D;0<br>$$<br>可得：<br>$$<br>Qx+c^\top+vA&#x3D;0<br>$$</p>
</li>
<li><p>complementary slackness</p>
<p>无</p>
</li>
<li><p>primal feasibility<br>$$<br>Ax-b&#x3D;0<br>$$</p>
</li>
<li></li>
<li><p>dual feaesibility</p>
<p>无</p>
</li>
</ul>
<p>综上，假设最优解为$x^{<em>}$，$v^{</em>}$其满足<br>$$<br>\begin{cases}Qx^*+c+A^Tv^*&#x3D;0\Ax^*&#x3D;b\end{cases}<br>$$<br>有<br>$$<br>\begin{bmatrix}Q&amp;A^T\A&amp;0\end{bmatrix}\begin{bmatrix}x^<em>\v^</em>\end{bmatrix}&#x3D;\begin{bmatrix}-c\b\end{bmatrix}<br>$$<br>下面我们还需证明$\begin{bmatrix}Q&amp;A^T\A&amp;0\end{bmatrix}$可逆</p>
<p>我们构造下面这个式子<br>$$<br>\begin{bmatrix}I&amp;0\-AQ^{-1}&amp;I\end{bmatrix}\begin{bmatrix}Q&amp;A^T\A&amp;0\end{bmatrix}\begin{bmatrix}I&amp;-Q^{-1}A^T\0&amp;I\end{bmatrix}&#x3D;\begin{bmatrix}Q&amp;0\0&amp;-AQ^{-1}A^T\end{bmatrix}<br>$$<br>因为$Q$是对称正定(SPD)的，所以$-AQ^{-1}A^T$也是对称正定(SPD)，所以$\begin{bmatrix}Q&amp;0\0&amp;-AQ^{-1}A^T\end{bmatrix}$是可逆的，即$\begin{bmatrix}Q&amp;A^T\A&amp;0\end{bmatrix}$可逆。</p>
<p>则此QP问题的解为：<br>$$<br>\begin{bmatrix}x^<em>\y^</em>\end{bmatrix}&#x3D;\begin{bmatrix}Q&amp;A^T\A&amp;0\end{bmatrix}^1!\begin{bmatrix}-c\b\end{bmatrix}<br>$$</p>
<h2 id="作业二：低维严格凸QP线性时间复杂度算法的补全"><a href="#作业二：低维严格凸QP线性时间复杂度算法的补全" class="headerlink" title="作业二：低维严格凸QP线性时间复杂度算法的补全"></a>作业二：低维严格凸QP线性时间复杂度算法的补全</h2><p>根据课程算法：</p>
<p><img src="/./304-2024-02-20-Math-Optimization/4.png" alt="4"></p>
<p>根据伪代码补全即可（详细代码见文件）</p>
<p>编译然后运行可执行文件结果如下：</p>
<p><img src="/./304-2024-02-20-Math-Optimization/5.png" alt="5"></p>
<h2 id="作业三：用PHR-ALM方法求解NMPC"><a href="#作业三：用PHR-ALM方法求解NMPC" class="headerlink" title="作业三：用PHR-ALM方法求解NMPC"></a>作业三：用PHR-ALM方法求解NMPC</h2><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>根据课程MPC问题可以表示成：<br>$$<br>\begin{aligned}\min_{u_{0:N}}J(s_1(u_{0:N}),\ldots,s_N(u_{0:N}),u_{0:N})\\mathrm{s.t.<del>}G(s_k(u_{0:N}),u_k)\leq0,\mathrm{</del>}\forall i\in{0,\ldots,N}\end{aligned}<br>$$<br>其中<br>$$<br>J(s_1,\ldots,s_N,u_0,\ldots,u_N):&#x3D;\sum_{k&#x3D;1}^N[(x_k-x_k^\mathrm{ref})^2+(y_k-y_k^\mathrm{ref})^2+w_v(a_k-a_{k-1})^2+w_\delta(\delta_k-\delta_{k-1})^2]<br>$$</p>
<p>$$<br>F({s_k},{u_k})&#x3D;{s_{k+1}},\mathrm{<del>}\forall\mathrm{</del>}i\in{0,\ldots,N}\quad\boldsymbol{\longleftrightarrow}\quad\boldsymbol{s_k}({u_{0:N}}),\mathrm{<del>}\forall\mathrm{</del>}i\in{1,\ldots,N}<br>$$</p>
<p>$$<br>\begin{aligned}<br>&amp;\mathrm{<del>}\forall\mathrm{</del>}k\in{0,\ldots,N} \<br>&amp;a_{\mathrm{min}}\leq a_{k}\leq a_{\mathrm{max}} \<br>&amp;\delta_{\mathrm{min}}\leq\delta_{k}\leq\delta_{\mathrm{max}}&amp; G(s_k,u_k)\leq0  \<br>&amp;v_{\mathrm{min}}\leq v_{k}\leq v_{\mathrm{max}}<br>\end{aligned}<br>$$</p>
<p>加入松弛变量，我们可以得到：<br>$$<br>G(s_k(u_{0:N}),u_k)+[s]^2&#x3D;0<br>$$<br>所以拉格朗日函数为：<br>$$<br>L(u_{0.N},\mu):&#x3D;J(s_{1}(u_{0.N}),…,s_{N}(u_{0.N}),u_{0.N})+\frac{\rho}{2}\biggr\Vert\max(\begin{array}{c}G(s_{k}(u_{0.N}),u_{k})+\frac{\mu}{\rho},0\end{array}\biggr\Vert^{2}<br>$$<br>然后进行迭代：<br>$$<br>\begin{cases}u_{0:N}\gets\arg\min L_p(u_{0:N},\mu)\\mu\gets\max[\mu+\rho G(s_k(u_{0:N}),u_k),0]\\rho\gets\min[(1+\gamma)\rho,\beta]\end{cases}<br>$$</p>
<h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><ol>
<li><p>根据说明安装<code>osqp</code></p>
</li>
<li><p>创建工作空间，将src文件夹复制进去。</p>
</li>
<li><p>编译<br><code>cd catkin_ws</code></p>
<p><code>catkin_make</code></p>
</li>
<li><p>执行launch文件<br><code>roslaunch mpc_car simulation.launch</code></p>
</li>
</ol>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>如下图所示：</p>
<p><img src="/./304-2024-02-20-Math-Optimization/6.gif" alt="6"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://example.com">Arvin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://example.com/2024/02/20/304-2024-02-20-Math-Optimization/">http://example.com/2024/02/20/304-2024-02-20-Math-Optimization/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/img/nacho.jepg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/02/26/305-2024-02-24-Math-Optimization/" title="机器人中的数值优化（四）"><div class="cover" style="background: None"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">机器人中的数值优化（四）</div></div><div class="info-2"><div class="info-item-1">文档维护：Arvin 网页部署：Arvin ▶ 写在前面：本文内容是作者在深蓝学院机器人中的数值优化学习时的笔记，作者按照自己的理解进行了记录，如果有错误的地方还请执政。如涉侵权，请联系删除。 锥规划（笔记）锥和对称锥尖锥如果一组点$\kappa\subseteq\mathbb{R}^n$满足以下条件，则称为尖锥：$$\begin{aligned}&amp;{\text{Conic:}\quad a\in\mathcal{K},\lambda\geq0\Rightarrow\lambda a\in\mathcal{K}}\&amp;{\text{Pointed:}\quad a\in\mathcal{K}\mathrm{and}-a\in\mathcal{K}\Rightarrow a&#x3D;0}\end{aligned}$$第一个条件即向量$a$在集合$\mathcal{K}$中，$\lambda\geq0$，则$\lambda a$也必然在集合$\mathcal{K}$中；第二个条件是若向量$a$在集合$\mathcal{K}$中，则向量$-a$不在集合$\mathcal...</div></div></div></a><a class="pagination-related" href="/2024/01/15/303-2024-01-17-Math-Optimization/" title="机器人中的数值优化（二）"><div class="cover" style="background: None"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">机器人中的数值优化（二）</div></div><div class="info-2"><div class="info-item-1">文档维护：Arvin 网页部署：Arvin ▶ 写在前面：本文内容是作者在深蓝学院机器人中的数值优化学习时的笔记，作者按照自己的理解进行了记录，如果有错误的地方还请执政。如涉侵权，请联系删除。 无约束优化拟牛顿法为什么要用拟牛顿法？一般情况下，当函数为曲线平滑的凸函数时，我们使用牛顿法。牛顿法如下： 通过二阶泰勒展开：$$f(\boldsymbol{x})\approx\hat{f}\left(\boldsymbol{x}\right)\triangleq f(\boldsymbol{x}_k)+\nabla f(\boldsymbol{x}_k)^T(\boldsymbol{x}-\boldsymbol{x}_k)+\frac12(\boldsymbol{x}-\boldsymbol{x}_k)^T\nabla^2f(\boldsymbol{x}_k)(\boldsymbol{x}-\boldsymbol{x}_k)	\tag{1}$$最小化二次近似：$$\begin{aligned}&amp;\nabla\hat{f}\left(\boldsymbol{x}\right)&#...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/nacho.jepg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Arvin</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">16</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%89%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96%EF%BC%88%E7%AC%94%E8%AE%B0%EF%BC%89"><span class="toc-number">1.</span> <span class="toc-text">有约束优化（笔记）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E7%B1%BB"><span class="toc-number">1.1.</span> <span class="toc-text">分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%8E%E7%BB%B4%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92%EF%BC%88LP%EF%BC%89"><span class="toc-number">1.2.</span> <span class="toc-text">低维线性规划（LP）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%8E%E7%BB%B4%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92%EF%BC%88QP%EF%BC%89"><span class="toc-number">1.3.</span> <span class="toc-text">低维二次规划（QP）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%89%E7%A7%8D%E5%BA%8F%E5%88%97%E6%97%A0%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"><span class="toc-number">1.4.</span> <span class="toc-text">约束优化的三种序列无约束优化方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%96%E7%82%B9%E7%BD%9A%E5%87%BD%E6%95%B0%E6%B3%95"><span class="toc-number">1.4.1.</span> <span class="toc-text">外点罚函数法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E7%82%B9%E7%BD%9A%E5%87%BD%E6%95%B0%E6%B3%95%EF%BC%9A%E9%9A%9C%E7%A2%8D%E5%87%BD%E6%95%B0%E6%B3%95"><span class="toc-number">1.4.2.</span> <span class="toc-text">内点罚函数法：障碍函数法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AD%89%E5%BC%8F%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%9A%84%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E6%9D%BE%E5%BC%9B%E6%B3%95"><span class="toc-number">1.4.3.</span> <span class="toc-text">等式约束优化问题的拉格朗日松弛法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E8%88%AC%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">1.5.</span> <span class="toc-text">一般约束优化的方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#KKT%E6%9D%A1%E4%BB%B6"><span class="toc-number">1.5.1.</span> <span class="toc-text">KKT条件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Powell-Hestense-Rockafellar-Augmented-Lagrangian-Method%EF%BC%88PHR-ALM%EF%BC%89"><span class="toc-number">1.5.2.</span> <span class="toc-text">Powell-Hestense-Rockafellar Augmented-Lagrangian-Method（PHR-ALM）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8"><span class="toc-number">1.6.</span> <span class="toc-text">应用</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A"><span class="toc-number">2.</span> <span class="toc-text">作业</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E4%B8%80%EF%BC%9A%E4%B8%A5%E6%A0%BC%E5%87%B8%E7%9A%84%E7%AD%89%E5%BC%8F%E7%BA%A6%E6%9D%9FQP%E7%9A%84KKT%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%B1%82%E8%A7%A3"><span class="toc-number">2.1.</span> <span class="toc-text">作业一：严格凸的等式约束QP的KKT推导和求解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E4%BA%8C%EF%BC%9A%E4%BD%8E%E7%BB%B4%E4%B8%A5%E6%A0%BC%E5%87%B8QP%E7%BA%BF%E6%80%A7%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%AE%97%E6%B3%95%E7%9A%84%E8%A1%A5%E5%85%A8"><span class="toc-number">2.2.</span> <span class="toc-text">作业二：低维严格凸QP线性时间复杂度算法的补全</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E4%B8%89%EF%BC%9A%E7%94%A8PHR-ALM%E6%96%B9%E6%B3%95%E6%B1%82%E8%A7%A3NMPC"><span class="toc-number">2.3.</span> <span class="toc-text">作业三：用PHR-ALM方法求解NMPC</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%9E%90"><span class="toc-number">2.3.1.</span> <span class="toc-text">分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C"><span class="toc-number">2.3.2.</span> <span class="toc-text">运行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-number">2.3.3.</span> <span class="toc-text">结果</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/18/hello-world/" title="Hello World">Hello World</a><time datetime="2025-08-18T07:15:49.592Z" title="Created 2025-08-18 15:15:49">2025-08-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/18/503-2025-08-18-Others-HexoBlog/" title="HEXO个人博客搭建"><img src="https://arvinzyj.github.io/2024/11/09/502-2024-11-09-others-Ubuntu/1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HEXO个人博客搭建"/></a><div class="content"><a class="title" href="/2025/08/18/503-2025-08-18-Others-HexoBlog/" title="HEXO个人博客搭建">HEXO个人博客搭建</a><time datetime="2025-08-17T16:00:00.000Z" title="Created 2025-08-18 00:00:00">2025-08-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/11/09/502-2024-11-09-Others-Ubuntu/" title="系统安装"><img src="https://arvinzyj.github.io/2024/11/09/502-2024-11-09-others-Ubuntu/1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="系统安装"/></a><div class="content"><a class="title" href="/2024/11/09/502-2024-11-09-Others-Ubuntu/" title="系统安装">系统安装</a><time datetime="2024-11-08T16:00:00.000Z" title="Created 2024-11-09 00:00:00">2024-11-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/04/08/309-2024-04-08-Math-AutoDriver/" title="自动驾驶预测与决策规划（三）"><div style="background: None"></div></a><div class="content"><a class="title" href="/2024/04/08/309-2024-04-08-Math-AutoDriver/" title="自动驾驶预测与决策规划（三）">自动驾驶预测与决策规划（三）</a><time datetime="2024-04-07T16:00:00.000Z" title="Created 2024-04-08 00:00:00">2024-04-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/20/308-2024-03-20-Math-AutoDriver/" title="自动驾驶预测与决策规划（二）"><div style="background: None"></div></a><div class="content"><a class="title" href="/2024/03/20/308-2024-03-20-Math-AutoDriver/" title="自动驾驶预测与决策规划（二）">自动驾驶预测与决策规划（二）</a><time datetime="2024-03-19T16:00:00.000Z" title="Created 2024-03-20 00:00:00">2024-03-20</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By Arvin</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>